## Эксперимент №5: проверка последствий обрезания инпута до n примеров.

### Проблема

Пусть нам на вход приходит $N$ примеров и $1$ запрос. Тогда в обычной реализации на вход модели будет подано $2N + 1$ токен. Что будет, если мы обрежем $N$ до некоторого меньшего $n$? Это можно сделать множеством разных способов, и в данном эксперименте мы рассмотрим два:

1. Мы берём последние $n$ примеров из инпута.
2. Мы берём случайные $n$ примеров из инпута.

Поскольку первый вариант идентичен простой обрезке контекста и его не имеет смысла тестировать, мы обрежем инпут после того, как пройдёт одна итерация с полным контекстом. Второй вариант мы реализуем таким же образом. С другой стороны, можно было бы рассмотреть ещё такие варианты:

- Каждую новую итерацию подаётся всё меньше и меньше примеров.
- Обрезка происходит после того, как сформировался эмбеддинг инпута, а не после первой итерации.
- Тестировать несколько различных $n$, чтобы посмотреть на то, как меняется результат при уменьшении контекста.
- Обучать модель делать обрезку со случайным $n$.

### Ожидаемый результат

Поскольку мы тренируем модель на задачу Next Token Prediction и соответственно ожидаем определённую структуру предсказаний модели, первый вариант окажется эффективнее. Также он может оказаться эффективнее ещё и потому, что элемент случайности значительно усложнит тренировку модели.

### Дизайн эксперимента

Мы используем тот же сеттинг, что и в предыдущем эксперименте. В данном случае в качестве Input Injection выбрано простое сложение, поскольку оно меньше всего зависит от случайности. Мы используем три зерна генерации: $42$, $451$ и $1984$. На этот раз мы ограничиваем контекст модели длиной $129$, т.е. в него влезет $64$ примера. Будем обучать модель при $n = 64$, $48$, $32$ и $24$. Размер батча для обоих моделей - $128$, $\text{lr} = 5e-4$.

### Результаты

