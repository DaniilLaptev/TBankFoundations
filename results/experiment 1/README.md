## Эксперимент №1: влияние скейлинга модели на результат и экстраполяцию.

### Проблема

Вполне ожидаемо, что модель большего размера будет лучше аппроксимировать искомую зависимость. То же относится к числу итераций - модель, обученная на большем $b$, скорее всего будет работать лучше. Однако не вполне ясно, как именно скейлинг будет влиять на результат. Нас интересуют два основных момента:

1. Если мы берём несколько моделей из разной весовой категории, может ли увеличение числа итераций помочь маленькой модели достичь результативности большой модели?
2. Как влияет увеличение размера модели на способность к экстраполяции при обучении на различном числе итераций?

### Ожидаемый результат

1. Может. Если взять достаточно большое число итераций, модель меньшего размера сможет достичь уровня модели большего размера.
2. Модели, обученные на одинаковом числе итераций, будут показывать примерно одинаковую способность к экстраполяции, но по-разному выучат аппроксимацию на итерациях от 1 до тренировочной.

### Дизайн эксперимента

Мы взяли три категории моделей со следующими характеристиками:

| Параметры | tiny | small | medium |
|---|:---:|:---:|:---:|
| Число слоёв | 1 | 2 | 4 |
| Число голов внимания | 2 | 4 | 8 |
| Размерность скрытого представления | 26 | 64 | 128 |
| Размерность скрытого MLP слоя | 128 | 256 | 768 |
| Суммарное число параметров | 1e4 | 1e5 | 1e6 |
| Learning rate | 1e-3 | 5e-4 | 5e-4 |

Каждую модель я обучал при $b = 1, 5, 10, 15$ и с тремя различными зёрнами генерации: $42$, $451$ и $1984$. Все модели обучались с одинаковым размером батча $(64)$, одинаковым числом итераций градиентного спуска $(7500)$ и одинаковым числом in-context примеров $(N = 63)$. За подробностями архитектуры обратитесь к файлу эксперимента и `transformer.py`).

### Результаты

Сравнение результатов работы моделей представлено на графике. Способ получения данных описан в README репозитория.

![Результат](./performance%201.svg)

Как видно из результатов, увеличение числа итераций позволяет на порядок улучшить качество работы модели. Кроме того, модель меньшего размера при увеличении $b$ способна достичь качества модели большего размера и даже превысить его. Этот результат был получен также и в исходной статье.

С другой стороны, у каждой модели имеется своя натуральная экспрессивность, и несмотря на то, что мы можем улучшить качество с помощью увеличения числа итераций, рано или поздно мы выйдем на плато. Таким образом, мы не можем бесконечно увеличивать $b$ ради бесконечного роста качества - оно будет ограничено исходной экспрессивностью, и, кроме того, увеличение $b$ также не бесплатное (это предмет отдельного исследования). 

Это, впрочем, вполне ожидаемый результат, однако он открывает некоторый простор для дальнейших исследований. Пусть натуральная экспрессивность нейросетевой модели $M$ выражается как число $\mathcal{E}_M$ и означает некоторую предельную эффективность модели (максимальную информационную ёмкость, максимальную аппроксимационную способность и т.п.). Тогда предельную эффективность Looped версии $M$, которую мы назовём $LM$, можно выразить как

```math
\mathcal{E}_{LM} = \mathbf{b}(\mathcal{E_M}),
```
где $\mathbf{b}$ - некоторая функция "скейлинга", определяющая, насколько улучшится потенциально возможная точность модели при увеличении $b$. Причём мы можем также ожидать, что $\mathcal{E}_{LM} = \mathcal{E}_M$ при $b = 1$.

Таким образом, одно из возможных направлений дальнейших исследований - это выяснение того, как увеличение $b$ улучшает экспрессивность модели, какова может быть форма $\mathbf{b}$, как она будет выглядеть на различных наборах данных и т.п.

---

Рассмотрим теперь способность к экстраполяции модели. По горизонтали отложено $b$, а по вертикали - значение валидационной метрики для обученной модели при заданном $b$.

![Результат](./extrapolation%201.svg)

Как видно из приведённых выше графиков, с увеличением размера модели график экстраполяции прижимается к нулю с обоих сторон (в $b = 1$ он тоже уменьшается). Это говорит о том, что модель большего размера лучше выучивает искомую закономерность, чем модель меньшего размера при том же самом $b$. Причём можно заметить, что модель `small`, обученная на $b = 10$ и $b = 15$, даже улучшает качество работы, если запустить её при большем числе итераций, вплоть до $b = 35$, а при $b = 50$ результат не хуже, чем при тренировочном числе итераций.

С другой стороны, если посмотреть на результат модели `medium`, мы обнаружим, что несмотря на хорошее качество работы при тренировочных $b$, её способность к экстраполяции по некоторым причинам хуже.

Рассмотрим также следующие графики:

![Результат](./extrapolation%202.svg)

Можно заметить, что модель `small` при увеличении $b > b_{\text{train}}$ не сильно теряет в качестве относительно тренировочного числа итераций, тогда как модель `medium` заметно ухудшает качество своей работы и ошибка начинает расти. В то же время, с увеличением числа тренировочных итераций способность к экстраполяции у модели `medium` становится всё лучше. В случае модели `tiny` мы наблюдаем даже улучшение качества при $b > 15$.

Можно сказать, что в терминах качества `medium` $>$ `small` $>$ `tiny`, но в терминах способности к экстраполяции `medium` $<$ `small` $<$ `tiny`.

Я описываю наблюдения следующим образом: 

> Чем больше модель, тем лучшего качества она достигает на $b_{\text{train}}$, и тем сложнее ей достичь того же качества на $b > b_{\text{train}}$.

По-хорошему необходимо рассмотреть ещё больше моделей различного размера. С другой стороны, это наблюдение вполне сходится с практикой обучения больших нейросетевых моделей: чем больше модель, тем больше ей требуется тренировочных примеров для достижения удовлетворительного качества на out-of-distribution данных, и тем более сложные сценарии тренировки ей требуются для того, чтобы не переобучиться (мы проводили эксперимент на довольно простых данных, которые описаны в readme репозитория). В данном случае просто речь идёт не только об OOD данных, а ещё и об OOD числе итераций.

Для описания причин наблюдаемых феноменов я рассматриваю следующие гипотезы в порядке приоритетности:

1. Я обучил модель `medium` на недостаточно большом объёме данных.
2. Большая модель лучше работает при большем $b$.
3. Экспрессивные модели способны переобучиться под $b_{\text{train}}$.

Если гипотезы 2 и 3 будут неверны, т.е. переобучение под какой-то конкретный $b$ невозможно, то это даст дополнительную уверенность в правильности гипотезы 1 и описания наблюдения: чем больше модель, тем больше примеров она требует для нормального обучения. С другой стороны, верными могут оказаться все три гипотезы одновременно.

Другое интересное наблюдение - вид значения функции потерь на различных $b$ для каждого зерна генерации:

![Результат](./loss%20comparison.svg)

Поскольку зерно фиксируется перед созданием модели, оптимизатор всегда стартует с одинаковых параметров для разных $b$. Затем он резко падает в ближайший локальный минимум, выравнивая значение функции потерь для различных $b$. В какой-то момент модели начинают расходиться, однако дальнейший ландшафт потерь (локальный, для полученного значения функции ошибки) выглядит так, будто отличается от прочих всего лишь на какой-то коэффициент (интересно, почему?). Кроме того, мы видим, что между 1 и 5 разрыв большой, между 5 и 10 разрыв поменьше, а между 10 и 15 разрыв практически незаметный. Это даёт дополнительные свидетельства в пользу вывода о том, что улучшение качества, получаемое за счёт увеличения $b$, имеет свои ограничения и в конце концов будет ничтожно мало.