{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import LinregDataset, save, train, set_seed\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import SinusoidalPositionEmbedding, Layer\n",
    "\n",
    "class LoopedTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.emb = nn.Linear(config.n_dims, config.hidden_dim)\n",
    "        \n",
    "        if config.pe == 'sinus':\n",
    "            self.pe = SinusoidalPositionEmbedding(config.hidden_dim, config.context)\n",
    "        elif config.pe == 'learnable':\n",
    "            self.pe = nn.Embedding(config.context, config.hidden_dim)\n",
    "        \n",
    "        self.layers = nn.Sequential(*[\n",
    "            Layer(config) for i in range(config.num_layers)\n",
    "        ])\n",
    "        self.out = nn.Linear(config.hidden_dim, config.n_dims)\n",
    "         \n",
    "    def _get_mask(self, config, input_dim, device = 'cpu'):\n",
    "        if config.mask_type == 'causal':\n",
    "            mask = torch.tril(torch.ones(input_dim, input_dim))\n",
    "            return mask.view(1, 1, input_dim, input_dim).to(device)\n",
    "        if config.mask_type == 'none':\n",
    "            return None\n",
    "        \n",
    "    def forward(self, x, b = 1):\n",
    "        \n",
    "        if len(x.shape) < 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        \n",
    "        # Довольно долго, но это рудимент от предыдущего кода.\n",
    "        # Можно перенести маску в буфер в init.\n",
    "        mask = self._get_mask(self.config, self.config.context, x.device)\n",
    "        \n",
    "        x = self.emb(x)\n",
    "        if self.config.pe == 'sinus':\n",
    "            x = x + self.pe(x)\n",
    "        elif self.config.pe == 'learnable':\n",
    "            x = x + self.pe(torch.arange(x.size(1), device=x.device))\n",
    "        \n",
    "        output = torch.zeros_like(x)\n",
    "        \n",
    "        pred_list = []\n",
    "        for i in range(b):\n",
    "            output = output + x\n",
    "            for layer in self.layers:\n",
    "                output, scores = layer(output, mask)\n",
    "            prediction = self.out(output)[:, ::2, 0]\n",
    "            pred_list.append(prediction)\n",
    "            \n",
    "        return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    n_dims:       int = 4\n",
    "    num_layers:   int = 1\n",
    "    attn_heads:   int = 4\n",
    "    hidden_dim:   int = 32\n",
    "    mlp_hidden:   int = 128\n",
    "    context:      int = 128\n",
    "    mask_type:    str = 'causal'\n",
    "    pe:           str = None\n",
    "    activation:   nn.Module = nn.GELU\n",
    "    \n",
    "def get_config(name, n_dims):\n",
    "    models = {\n",
    "        'spe_cm': (Config(\n",
    "            n_dims = n_dims, num_layers = 2,\n",
    "            attn_heads = 4, hidden_dim = 64,\n",
    "            mlp_hidden = 256, context = 127,\n",
    "            mask_type = 'causal', pe = 'sinus'\n",
    "        ), 5e-4, 64, 32),\n",
    "        \n",
    "        'spe': (Config(\n",
    "            n_dims = n_dims, num_layers = 2,\n",
    "            attn_heads = 4, hidden_dim = 64,\n",
    "            mlp_hidden = 256, context = 127,\n",
    "            mask_type = 'none', pe = 'sinus'\n",
    "        ), 5e-4, 64, 32),\n",
    "        \n",
    "        'cm': (Config(\n",
    "            n_dims = n_dims, num_layers = 2,\n",
    "            attn_heads = 4, hidden_dim = 64,\n",
    "            mlp_hidden = 256, context = 127,\n",
    "            mask_type = 'causal', pe = None\n",
    "        ), 5e-4, 64, 32),\n",
    "        \n",
    "        'none': (Config(\n",
    "            n_dims = n_dims, num_layers = 2,\n",
    "            attn_heads = 4, hidden_dim = 64,\n",
    "            mlp_hidden = 256, context = 127,\n",
    "            mask_type = 'none', pe = None\n",
    "        ), 5e-4, 64, 32),\n",
    "        \n",
    "        'lpe': (Config(\n",
    "            n_dims = n_dims, num_layers = 2,\n",
    "            attn_heads = 4, hidden_dim = 64,\n",
    "            mlp_hidden = 256, context = 127,\n",
    "            mask_type = 'none', pe = 'learnable'\n",
    "        ), 5e-4, 64, 32),\n",
    "        \n",
    "        'lpe_cm': (Config(\n",
    "            n_dims = n_dims, num_layers = 2,\n",
    "            attn_heads = 4, hidden_dim = 64,\n",
    "            mlp_hidden = 256, context = 127,\n",
    "            mask_type = 'causal', pe = 'learnable'\n",
    "        ), 5e-4, 64, 32),\n",
    "    }\n",
    "    return models[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from torch.optim import Adam\n",
    "\n",
    "n_dims = 8\n",
    "mean, std = 0, 1\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "seeds = [42, 451, 1984]\n",
    "models = ['none', 'cm', 'spe', 'lpe', 'spe_cm', 'lpe_cm']\n",
    "bs = [1, 5]\n",
    "\n",
    "for name in models:\n",
    "    for b in bs:\n",
    "        for seed in seeds:\n",
    "        \n",
    "            config, lr, train_bsize, test_bsize = get_config(name, n_dims)\n",
    "            n_points = (config.context + 1) // 2\n",
    "            \n",
    "            train_loader = DataLoader(LinregDataset(\n",
    "                n_dims = n_dims, n_points = n_points,\n",
    "                mean = mean, std = std, random = True,\n",
    "                device = device\n",
    "            ), batch_size = train_bsize)\n",
    "            test_loader = DataLoader(LinregDataset(\n",
    "                n_dims = n_dims, n_points = n_points,\n",
    "                mean = mean, std = std, random = True,\n",
    "                total = test_bsize * 10, device = device\n",
    "            ), batch_size = test_bsize)\n",
    "\n",
    "            set_seed(seed)\n",
    "            \n",
    "            model = LoopedTransformer(config).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            if 'spe' in name:\n",
    "                pe = 'spe'\n",
    "            elif 'lpe' in name:\n",
    "                pe = 'lpe'\n",
    "            else:\n",
    "                pe = 'none'\n",
    "            cm = 'cm' in name\n",
    "                \n",
    "            run_name = f'{name}_{b}_{seed}'\n",
    "            run = wandb.init(\n",
    "                project = 'Looped Transformer',\n",
    "                name = run_name,\n",
    "                config = {\n",
    "                    'name': f'exp3_{name}_{b}',\n",
    "                    'experiment': 3,\n",
    "                    'model': name,\n",
    "                    'b': b,\n",
    "                    'train batch size': train_bsize,\n",
    "                    'test batch size': test_bsize,\n",
    "                    'lr': lr,\n",
    "                    'seed': seed,\n",
    "                    'N': n_points - 1,\n",
    "                    'pe': pe,\n",
    "                    'cm': cm\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            loss_history, eval_history = train(\n",
    "                model, train_loader, test_loader, optimizer, \n",
    "                b = b, steps = 7500, run = run, log_every = 75\n",
    "            )\n",
    "                \n",
    "            run.finish()\n",
    "            \n",
    "            save(3, run_name, loss_history, eval_history)\n",
    "            torch.save(model, './results/experiment 3/models/' + run_name + '.pt')\n",
    "            \n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a9e71a006741cdb457089f71027d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from itertools import product\n",
    "\n",
    "n_dims = 8\n",
    "mean, std = 0, 1\n",
    "\n",
    "seeds = [42, 451, 1984]\n",
    "models = ['none', 'cm', 'spe', 'lpe', 'spe_cm', 'lpe_cm']\n",
    "bs = [1, 5]\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "runs = []\n",
    "for model, b in product(models, bs):\n",
    "    runs.append((model, b))\n",
    "    \n",
    "test_seed = 4815163242 % 2**31\n",
    "num_launches = 10\n",
    "    \n",
    "results = {}\n",
    "pbar = tqdm(range(len(runs) * num_launches * 3))\n",
    "for (name, b) in runs:\n",
    "    config, lr, train_bsize, test_bsize = get_config(name, n_dims)\n",
    "    n_points = (config.context + 1) // 2\n",
    "    \n",
    "    set_seed(test_seed)\n",
    "    res = []\n",
    "    for seed in seeds:\n",
    "        model = torch.load(f'./results/experiment 3/models/{name}_{b}_{seed}.pt')\n",
    "            \n",
    "        for i in range(num_launches):\n",
    "            \n",
    "            std = torch.rand((1,)).item() * 2\n",
    "            loader = DataLoader(LinregDataset(\n",
    "                n_dims = n_dims, n_points = n_points,\n",
    "                mean = mean, std = std, random = True,\n",
    "                total = 128 * 10, device = device\n",
    "            ), batch_size = 128)\n",
    "            \n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for (x, y) in loader:\n",
    "                    \n",
    "                    preds = model(x[:, :-1], b)\n",
    "                    preds = torch.stack(preds)\n",
    "                    targs = torch.stack([y] * b)\n",
    "                    \n",
    "                    # First by predictions, then by batches\n",
    "                    loss = (targs[:,:,-1] - preds[:,:,-1]).square().mean(dim=0).mean()\n",
    "                    \n",
    "                    total += loss.item() / loader.dataset.n_dims\n",
    "            res.append(total / len(loader))\n",
    "            pbar.set_description(f'Run \\'{name}_{b}\\', seed {seed}...')\n",
    "            pbar.update(1)\n",
    "                \n",
    "    results[f'{name}_{b}'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'none_1': [0.0007617591239977628,\n",
       "  0.16063800901174546,\n",
       "  0.06604306474328041,\n",
       "  1.0238654613494873,\n",
       "  1.6386443734169007,\n",
       "  0.6003895491361618,\n",
       "  2.2944544196128844,\n",
       "  3.3825491666793823,\n",
       "  0.3290462464094162,\n",
       "  1.2762592792510987,\n",
       "  0.6742267310619354,\n",
       "  3.141448736190796,\n",
       "  0.9908895373344422,\n",
       "  0.35089159607887266,\n",
       "  0.2803729087114334,\n",
       "  0.07493693009018898,\n",
       "  0.09332494884729385,\n",
       "  2.6483384370803833,\n",
       "  1.0674304366111755,\n",
       "  0.022384471818804742,\n",
       "  2.101412773132324,\n",
       "  3.437103033065796,\n",
       "  1.5022632718086242,\n",
       "  0.03170825019478798,\n",
       "  3.2148009061813356,\n",
       "  2.2701428174972533,\n",
       "  0.03521009273827076,\n",
       "  0.6284147381782532,\n",
       "  3.0248604297637938,\n",
       "  0.36026417911052705],\n",
       " 'none_5': [0.015313539281487465,\n",
       "  0.16762558221817017,\n",
       "  0.06613628529012203,\n",
       "  1.0227354764938354,\n",
       "  1.6741648197174073,\n",
       "  0.6005726456642151,\n",
       "  2.2859718799591064,\n",
       "  3.3874714851379393,\n",
       "  0.3365749180316925,\n",
       "  1.2562395572662353,\n",
       "  0.6721282243728638,\n",
       "  3.0953964471817015,\n",
       "  0.9927003383636475,\n",
       "  0.36843656599521635,\n",
       "  0.29628839790821077,\n",
       "  0.062445228546857835,\n",
       "  0.08284396082162857,\n",
       "  2.638846230506897,\n",
       "  1.045394879579544,\n",
       "  0.023048234358429908,\n",
       "  2.085489797592163,\n",
       "  3.4305413961410522,\n",
       "  1.4916748642921447,\n",
       "  0.012895602080971003,\n",
       "  3.2353943586349487,\n",
       "  2.269135582447052,\n",
       "  0.007379666157066822,\n",
       "  0.6323355972766876,\n",
       "  3.025619649887085,\n",
       "  0.3620809465646744],\n",
       " 'cm_1': [0.017190277203917505,\n",
       "  0.11160079836845398,\n",
       "  0.05579117834568024,\n",
       "  0.4440021812915802,\n",
       "  0.8516131699085235,\n",
       "  0.3029373541474342,\n",
       "  1.2083720028400422,\n",
       "  2.001062500476837,\n",
       "  0.17653682380914687,\n",
       "  0.5945823878049851,\n",
       "  0.29742222726345063,\n",
       "  2.1856651663780213,\n",
       "  0.4664479285478592,\n",
       "  0.1897926539182663,\n",
       "  0.1618697389960289,\n",
       "  0.040907195582985875,\n",
       "  0.054953718185424806,\n",
       "  1.8000605940818786,\n",
       "  0.576387345790863,\n",
       "  0.01887658527120948,\n",
       "  1.192528533935547,\n",
       "  2.0109751224517822,\n",
       "  0.7332816600799561,\n",
       "  0.010601397790014743,\n",
       "  1.8335737943649293,\n",
       "  1.1530491173267365,\n",
       "  0.005471225967630744,\n",
       "  0.31405610889196395,\n",
       "  1.6162704348564148,\n",
       "  0.20028650611639023],\n",
       " 'cm_5': [0.009684536512941122,\n",
       "  0.056640011444687846,\n",
       "  0.04672318138182163,\n",
       "  0.13182848542928696,\n",
       "  0.2648283511400223,\n",
       "  0.08568933457136155,\n",
       "  0.425108990073204,\n",
       "  0.8194596648216248,\n",
       "  0.06013726033270359,\n",
       "  0.1740941658616066,\n",
       "  0.09674280658364295,\n",
       "  0.88812375664711,\n",
       "  0.1483956128358841,\n",
       "  0.06462712958455086,\n",
       "  0.05734997242689133,\n",
       "  0.03597095739096403,\n",
       "  0.040866436809301375,\n",
       "  0.6369706630706787,\n",
       "  0.1849879279732704,\n",
       "  0.01760809710249305,\n",
       "  0.35481446981430054,\n",
       "  0.840222829580307,\n",
       "  0.2189135581254959,\n",
       "  0.03384878933429718,\n",
       "  0.7352194130420685,\n",
       "  0.3938363164663315,\n",
       "  0.02706151120364666,\n",
       "  0.08595471531152725,\n",
       "  0.6350482106208801,\n",
       "  0.06330927796661853],\n",
       " 'spe_1': [0.0018860436277464033,\n",
       "  0.17094437181949615,\n",
       "  0.06763468235731125,\n",
       "  1.111732679605484,\n",
       "  1.8066307306289673,\n",
       "  0.6328170597553253,\n",
       "  2.4549721479415894,\n",
       "  3.5627241134643555,\n",
       "  0.3538883000612259,\n",
       "  1.3746562123298645,\n",
       "  0.7112255215644836,\n",
       "  3.383642053604126,\n",
       "  1.1084395945072174,\n",
       "  0.3763822793960571,\n",
       "  0.29914509654045107,\n",
       "  0.05364829339087009,\n",
       "  0.07544315755367278,\n",
       "  2.8825568199157714,\n",
       "  1.2047196269035338,\n",
       "  0.018173574190586805,\n",
       "  2.3026206493377686,\n",
       "  3.620690941810608,\n",
       "  1.665112316608429,\n",
       "  0.009471443435177206,\n",
       "  3.440723490715027,\n",
       "  2.48238742351532,\n",
       "  0.0011789187439717353,\n",
       "  0.6680076599121094,\n",
       "  3.228786253929138,\n",
       "  0.39200599789619445],\n",
       " 'spe_5': [0.00436445907689631,\n",
       "  0.13550007566809655,\n",
       "  0.06340591870248317,\n",
       "  0.49922730326652526,\n",
       "  0.8982434093952179,\n",
       "  0.30809761881828307,\n",
       "  1.2897295355796814,\n",
       "  1.9656471848487853,\n",
       "  0.21802060455083846,\n",
       "  0.633861294388771,\n",
       "  0.6267598927021026,\n",
       "  2.9991666793823244,\n",
       "  0.9695888340473175,\n",
       "  0.359895721077919,\n",
       "  0.28429814875125886,\n",
       "  0.06212136559188366,\n",
       "  0.08267058953642845,\n",
       "  2.4922563314437864,\n",
       "  1.0271806418895721,\n",
       "  0.02588603738695383,\n",
       "  1.1249420404434205,\n",
       "  1.8707419395446778,\n",
       "  0.7776455700397491,\n",
       "  0.012205517664551736,\n",
       "  1.7797494888305665,\n",
       "  1.1704254746437073,\n",
       "  0.0039595110109075906,\n",
       "  0.3038013458251953,\n",
       "  1.66816645860672,\n",
       "  0.22707665711641312],\n",
       " 'lpe_1': [0.0037301452597603203,\n",
       "  0.17253974378108977,\n",
       "  0.06924583725631236,\n",
       "  1.114266437292099,\n",
       "  1.8113741040229798,\n",
       "  0.6369258403778076,\n",
       "  2.4638984203338623,\n",
       "  3.5283556938171388,\n",
       "  0.3553234487771988,\n",
       "  1.3784943222999573,\n",
       "  0.7157491862773895,\n",
       "  3.3835867404937745,\n",
       "  1.1148081123828888,\n",
       "  0.381743973493576,\n",
       "  0.30240819305181504,\n",
       "  0.05612058714032173,\n",
       "  0.07708469107747078,\n",
       "  2.8640945672988893,\n",
       "  1.1883767604827882,\n",
       "  0.018859155289828778,\n",
       "  2.3004012942314147,\n",
       "  3.6135969161987305,\n",
       "  1.6654425382614135,\n",
       "  0.010427009407430887,\n",
       "  3.4455575466156008,\n",
       "  2.4779558181762695,\n",
       "  0.0021839429391548038,\n",
       "  0.6691214919090271,\n",
       "  3.23156533241272,\n",
       "  0.39231365323066714],\n",
       " 'lpe_5': [0.008139927312731743,\n",
       "  0.17712861448526382,\n",
       "  0.07379467487335205,\n",
       "  1.116745412349701,\n",
       "  1.8195025324821472,\n",
       "  0.644640302658081,\n",
       "  2.463956832885742,\n",
       "  3.5210179567337034,\n",
       "  0.36095057129859925,\n",
       "  1.3865916848182678,\n",
       "  0.3866010129451752,\n",
       "  1.854889166355133,\n",
       "  0.5101991713047027,\n",
       "  0.2641815334558487,\n",
       "  0.2222676932811737,\n",
       "  0.053140643239021304,\n",
       "  0.07406594157218933,\n",
       "  1.5174477458000184,\n",
       "  0.6041385650634765,\n",
       "  0.020233798213303088,\n",
       "  2.292117178440094,\n",
       "  3.6413734674453737,\n",
       "  1.6776529908180238,\n",
       "  0.010788266733288764,\n",
       "  3.4288426637649536,\n",
       "  2.4683329105377196,\n",
       "  0.0023235253524035216,\n",
       "  0.6698487818241119,\n",
       "  3.2245449304580687,\n",
       "  0.4004498362541199],\n",
       " 'spe_cm_1': [0.0007145651848986745,\n",
       "  0.06382394805550576,\n",
       "  0.043835879862308504,\n",
       "  0.11801705732941628,\n",
       "  0.23154256790876387,\n",
       "  0.08777134269475936,\n",
       "  0.4019541501998901,\n",
       "  0.874475747346878,\n",
       "  0.06192297488451004,\n",
       "  0.15881040692329407,\n",
       "  0.07381693199276924,\n",
       "  0.5278785347938537,\n",
       "  0.1110905148088932,\n",
       "  0.0564978577196598,\n",
       "  0.050354141369462015,\n",
       "  0.03082079831510782,\n",
       "  0.03604383990168571,\n",
       "  0.442728728055954,\n",
       "  0.12386105209589005,\n",
       "  0.016004267521202563,\n",
       "  1.8563259601593018,\n",
       "  3.1960254669189454,\n",
       "  1.3764561414718628,\n",
       "  0.010788936167955399,\n",
       "  2.972380542755127,\n",
       "  2.080376935005188,\n",
       "  0.0023462207056581972,\n",
       "  0.5168785274028778,\n",
       "  2.7590139865875245,\n",
       "  0.314130125939846],\n",
       " 'spe_cm_5': [0.002855857345275581,\n",
       "  0.13931210190057755,\n",
       "  0.060937384888529775,\n",
       "  0.8765879452228547,\n",
       "  1.4787327289581298,\n",
       "  0.5029374092817307,\n",
       "  2.0080174088478087,\n",
       "  2.9552060842514036,\n",
       "  0.28271777629852296,\n",
       "  1.0541712641716003,\n",
       "  0.027605118043720723,\n",
       "  0.3060284435749054,\n",
       "  0.03910475485026836,\n",
       "  0.028105227649211882,\n",
       "  0.025441860780119896,\n",
       "  0.026850247383117677,\n",
       "  0.02923654709011316,\n",
       "  0.21271526515483857,\n",
       "  0.04627928286790848,\n",
       "  0.014371182676404715,\n",
       "  0.21016161143779755,\n",
       "  0.5607348084449768,\n",
       "  0.1177571326494217,\n",
       "  0.008468683063983917,\n",
       "  0.42460193037986754,\n",
       "  0.24122589081525803,\n",
       "  0.0014808777486905456,\n",
       "  0.044901345297694205,\n",
       "  0.3847465991973877,\n",
       "  0.03741398490965366],\n",
       " 'lpe_cm_1': [0.005850876588374377,\n",
       "  0.04010100923478603,\n",
       "  0.023337913677096367,\n",
       "  0.179974664747715,\n",
       "  0.313263601064682,\n",
       "  0.11481317281723022,\n",
       "  0.552039521932602,\n",
       "  0.9298282325267792,\n",
       "  0.06522808857262134,\n",
       "  0.23339365124702455,\n",
       "  0.12380419149994851,\n",
       "  0.800299733877182,\n",
       "  0.18191626220941542,\n",
       "  0.071795242279768,\n",
       "  0.061042149737477305,\n",
       "  0.021702080219984054,\n",
       "  0.02657246235758066,\n",
       "  0.6536625266075134,\n",
       "  0.23167737126350402,\n",
       "  0.011416690330952406,\n",
       "  0.269277012348175,\n",
       "  0.603083199262619,\n",
       "  0.17259820997714997,\n",
       "  0.0079240835737437,\n",
       "  0.5332087755203248,\n",
       "  0.30851762294769286,\n",
       "  0.0010692351032048463,\n",
       "  0.06682238020002843,\n",
       "  0.47271354794502257,\n",
       "  0.0496444009244442],\n",
       " 'lpe_cm_5': [0.014415673911571503,\n",
       "  0.03062529508024454,\n",
       "  0.030678466334939,\n",
       "  0.061805568262934686,\n",
       "  0.12064805179834366,\n",
       "  0.042438137158751485,\n",
       "  0.21643585711717606,\n",
       "  0.4261344879865646,\n",
       "  0.0323095565661788,\n",
       "  0.08076151981949806,\n",
       "  0.027588843554258346,\n",
       "  0.3298797070980072,\n",
       "  0.04238669350743294,\n",
       "  0.017587089072912933,\n",
       "  0.0153193399310112,\n",
       "  0.009771168790757656,\n",
       "  0.010053987987339497,\n",
       "  0.22615316212177278,\n",
       "  0.04828744493424893,\n",
       "  0.008212163439020514,\n",
       "  0.1467899963259697,\n",
       "  0.4219916969537735,\n",
       "  0.08181333616375923,\n",
       "  0.0065913836937397715,\n",
       "  0.3408632516860962,\n",
       "  0.20040235072374343,\n",
       "  0.000523724319646135,\n",
       "  0.02836841456592083,\n",
       "  0.3141463339328766,\n",
       "  0.0240634024143219]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/experiment 3/data/evaluation.json', 'w') as f:\n",
    "    f.write(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
